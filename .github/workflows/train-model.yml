name: Train Power Model on GitHub Runner

on:
  workflow_call:
    secrets:
      self_hosted_github_token:
        description: 'The GitHub token to use'
        required: true
      aws_access_key_id:
        description: 'The AWS access key id to use'
        required: true
      aws_secret_access_key:
        description: 'The AWS secret access key to use'
        required: true
      aws_region:
        description: 'The AWS region to use'
        required: true
    inputs:
      pipeline_name: 
        description: 'Pipeline name'
        required: true
        type: string
      github_repo:
        description: 'The GitHub repo to use'
        required: true
        type: string
      ami_id:
        description: 'The AMI ID to use for the EC2 instance'
        required: true
        type: string
      instance_type:
        description: 'The instance type to use for the EC2 instance'
        required: true
        type: string
      model_server_image:
        description: 'Kepler Model Server image'
        required: true
        type: string
      output_type:
        description: 'Model output type (AbsPower, DynPower)'
        required: false
        type: string
        default: AbsPower
      energy_source:
        description: 'Target energy source'
        required: false
        type: string
        default: rapl-sysfs
      feature_group:
        description: 'Target feature group'
        required: false
        type: string
        default: BPFOnly
      trainers:
        description: 'Model trainer list (delimit: ,)'
        required: false
        type: string
        default: XgboostFitTrainer

env:
  AMI_ID: ${{ inputs.ami_id }}
  AWS_REGION: ${{ secrets.aws_region }}
  AWS_ACCESS_KEY_ID: ${{ secrets.aws_access_key_id }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.aws_secret_access_key }}
  KIND_CLUSTER_NAME: kind
  KUBECONFIG: /tmp/kubeconfig

jobs:
  check-data:
    name: Check data available
    runs-on: ubuntu-latest

    outputs:
      available: ${{ steps.check-data.outputs.available }}

    steps:
      - name: Checkout
        id: checkout
        uses: actions/checkout@v4

      - name: Install aws cli
        run: |
              sudo apt-get update
              sudo apt-get install -y python3-pip bc
              sudo pip3 install awscli
          
      - name: Check Data
        id: check-data
        run: |
          export HOST_MNT_PATH=$(pwd)/mnt
          
          if [ "$AWS_SECRET_ACCESS_KEY" == "" ]; then
              echo "available=false" >> "$GITHUB_OUTPUT"
          else
              if ./hack/aws_helper.sh check_data ${{ inputs.instance_type }}-${AMI_ID}; then
                  echo "available=true" >> "$GITHUB_OUTPUT"
              else
                  echo "available=false" >> "$GITHUB_OUTPUT"
              fi
          fi
          
  retrain-model:
    needs: check-data
    if: ${{ needs.check-data.outputs.available == 'true' }}
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        id: checkout
        uses: actions/checkout@v4

      - name: Install aws cli
        run: |
              sudo apt-get update
              sudo apt-get install -y python3-pip bc
              sudo pip3 install awscli

      - name: use Kepler action to deploy cluster
        uses: sustainable-computing-io/kepler-action@v0.0.7
        with:
          ebpfprovider: libbpf
          cluster_provider: kind
          prometheus_enable: true
          tekton_enable: true

      - name: Prepare PVC
        working-directory: model_training/tekton
        run: |
          kubectl apply -f pvc/hostpath.yaml

      - name: Deploy S3 Secret
        run: |
          cat <<EOF | kubectl apply -f -
          apiVersion: v1
          kind: Secret
          metadata:
            name: aws-cos-secret
          type: Opaque
          stringData:
            accessKeyID: ${{ secrets.AWS_ACCESS_KEY_ID }}
            accessSecret: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
            regionName: ${{ secrets.AWS_REGION }}
            bucketName: kepler-power-model
          EOF

      - name: Deploy Tasks and Pipelines
        working-directory: model_training/tekton
        run: |
          kubectl apply -f tasks
          kubectl apply -f tasks/s3
          kubectl apply -f pipelines

      - name: Run Tekton Pipeline with S3Push
        run: |
          cat <<EOF | kubectl apply -f -
          apiVersion: tekton.dev/v1
          kind: PipelineRun
          metadata:
            name: self-hosted-aws-train
          spec:
            timeouts:
              pipeline: "6h"
              tasks: "5h50m"
            workspaces:
            - name: mnt
              persistentVolumeClaim:
                claimName: task-pvc
            params:
            - name: ENERGY_SOURCE
              value: ${{ inputs.energy_source }}
            - name: MODEL_SERVER_IMAGE
              value: ${{ inputs.model_server_image }}
            - name: PIPELINE_NAME
              value: ${{ inputs.pipeline_name }}
            - name: COS_PROVIDER
              value: aws
            - name: COS_SECRET_NAME
              value: aws-cos-secret
            - name: MACHINE_ID
              value: ${{ inputs.instance_type }}-${AMI_ID}
            - name: ABS_TRAINERS
              value: ${{ inputs.trainers }}
            - name: DYN_TRAINERS
              value: ${{ inputs.trainers }}
            pipelineRef:
              name: complete-retrain-pipeline
          EOF

      - name: Wait for PipelineRun
        run: |
          ./hack/k8s_helper.sh wait_for_pipelinerun self-hosted-aws-train